import torch
import joblib
import pandas as pd
import numpy as np
import pathlib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import torch.nn as nn

# ---- 1. åŠ è½½æ•°æ® ----
data_file = r"C:\Users\26876\Desktop\Math548\Project\Option_put_price_dataset_mpmath.parquet"
model_file = r"C:\Users\26876\Desktop\Math548\Project\model.pt"
scaler_file = r"C:\Users\26876\Desktop\Math548\Project\scalers.pkl"

# åŠ è½½æ•°æ®
df = pd.read_parquet(data_file)
scalers = joblib.load(scaler_file)

in_cols = scalers["in_cols"]
out_cols = scalers["out_cols"]
scX = scalers["scX"]
scY = scalers["scY"]

# ---- 2. åˆ†å‰²æ•°æ®ï¼ˆä¸¥æ ¼æŒ‰ç…§ t_K åˆ†å±‚ï¼‰----
if "t" not in df.columns or "K" not in df.columns:
    raise ValueError("æ•°æ®ä¸­ç¼ºå°‘ 't' å’Œ 'K' åˆ—ï¼Œæ— æ³•è¿›è¡Œ stratified splitï¼")

strata = df["t"].astype(str) + "_" + df["K"].astype(str)

train_df, test_df = train_test_split(
    df, test_size=0.05, stratify=strata, random_state=2025
)

print(f"ğŸ“¦ Train size: {len(train_df)}, Test size: {len(test_df)}")

# ---- 3. ä»æµ‹è¯•é›†ä¸­éšæœºå–100ä¸ªç‚¹ ----
np.random.seed(42)
sample_df = test_df.sample(n=200, random_state=2025)

X = sample_df[in_cols].values
Y_true = sample_df[out_cols].values

# æ ‡å‡†åŒ–ï¼ˆæ³¨æ„ä½¿ç”¨è®­ç»ƒæ—¶çš„æ ‡å‡†åŒ–å™¨ï¼‰
X_std = scX.transform(X)

# ---- 4. å®šä¹‰ç½‘ç»œå¹¶åŠ è½½æƒé‡ ----
def get_act(name):
    name = name.lower()
    if name in ("linear", "none"): return nn.Identity()
    if name == "relu": return nn.ReLU()
    if name == "elu": return nn.ELU()
    if name == "leaky": return nn.LeakyReLU(0.01)
    if name == "tanh": return nn.Tanh()
    raise ValueError(f"unknown activation {name}")

class GenericNet(nn.Module):
    def __init__(self, dim_in, dim_out, hidden, layers, act="elu", out_act="linear"):
        super().__init__()
        if isinstance(hidden, int):
            hidden = [hidden] * layers
        blocks, in_d = [], dim_in
        for h in hidden:
            blocks += [nn.Linear(in_d, h), get_act(act)]
            in_d = h
        blocks += [nn.Linear(in_d, dim_out), get_act(out_act)]
        self.net = nn.Sequential(*blocks)

    def forward(self, x):
        return self.net(x)

# å»ºç«‹å’Œè®­ç»ƒæ—¶ä¸€æ¨¡ä¸€æ ·çš„ç½‘ç»œ
net = GenericNet(
    dim_in=len(in_cols),
    dim_out=len(out_cols),
    hidden=[64, 64, 32],  # ğŸ”¥ è¿™é‡Œä¸€å®šè¦å’Œè®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼
    layers=3,
    act="elu",
    out_act="linear",
).double()

net.load_state_dict(torch.load(model_file))
net.eval()

# ---- 5. é¢„æµ‹ ----
with torch.no_grad():
    preds_std = net(torch.tensor(X_std, dtype=torch.double)).numpy()

# åæ ‡å‡†åŒ–
preds = scY.inverse_transform(preds_std)

# ---- 6. æ¯”è¾ƒ true vs pred ----
plt.figure(figsize=(8,6))
plt.scatter(range(len(Y_true)), Y_true, color="green", label="True", marker="o", alpha=0.7)
plt.scatter(range(len(preds)), preds, color="blue", label="Predicted", marker="x", alpha=0.7)
plt.xlabel("Sample Index")
plt.ylabel("Value")
plt.title("True vs Predicted Values (100 random samples from Test Set)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# ---- 7. è®¡ç®— RMSE ----
rmse = np.sqrt(((Y_true - preds) ** 2).mean())
print(f"ğŸ RMSE on 100 test samples = {rmse:.6f}")
